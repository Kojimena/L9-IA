{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inteligencia Artificial - Laboratorio 9 -\n",
    "### Integrantes\n",
    "- Mark Albrand/21004\n",
    "- Jimena Hernandez/21199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks 1 - Teoría\n",
    "\n",
    "1. Diga cual es la diferencia entre Modelos de Markov y Hidden Markov Models\n",
    "\n",
    "La principal diferencia entre un Modelo de Markov y un Modelo de Markov Oculto (HMM) es que en el HMM no hay una correspondencia directa entre las observaciones y los estados del modelo. En un HMM, los estados son ocultos y solo las observaciones son visibles (Purdue University, s.f.).\n",
    "Esto hace que no sea posible determinar de manera directa en qué estado estaba la máquina cuando produjo una determinada observación. En cambio, en un modelo de Markov, los estados son visibles y se puede determinar directamente en qué estado estaba la máquina en un momento dado.\n",
    "\n",
    "*Purdue University. (s. f.). Markov chains and hidden Markov models. https://www.stat.purdue.edu/~junxie/topic3.pdf*\n",
    "\n",
    "2. Investigue qué son los factorial HMM (Hidden Markov Models)\n",
    "Estos modelos combinan la estructura de transición de estados de los HMM con las representaciones distribuidas de los CVQ. Esto puede representarse de mejor forma en la siguiente figura:\n",
    "<div style=\"width:400px\">\n",
    "\n",
    "![ Hidden Markov model & Factorial hidden Markov model](mkd.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "Cada modelo de Markov subyacente, tiene un estado específico y su propia matriz que determina las probabilidades de transición entre estados. Asimismo en los CVQ cada estado dentro de un modelo es exclusivo.\n",
    "\n",
    "Los estados en estos modelos son representados por vectores que principalmente tienen 0's excepto por un solo uno, indicando el estado activo.\n",
    "*Ghahramani, Z., & Jordan, M. I. (1996). Factorial hidden Markov models (A.I. Memo No. 1561; C.B.C.L. Paper No. 130). Massachusetts Institute of Technology, Artificial Intelligence Laboratory and Center for Biological and Computational Learning, Department of Brain and Cognitive Sciences.*\n",
    "\n",
    "3. Especifique en sus propias palabras el algoritmo Forward Backward para HMM\n",
    "\n",
    "El algoritmo forward-backward se usa para calcular la probabilidad de que un HMM genere una secuencia de observaciones dadas. El algoritmo se divide en dos pasos: el paso forward y el paso backward.\n",
    "\n",
    "    En el paso forward se calcula la probabilidad de ver las observaciones hasta un momento específico, dado que el modelo está en un estado particular en un momento dado.\n",
    "    En el paso backward se calcula la probabilidad de ver las observaciones restantes, dado que el modelo está en un estado particular en un momento dado. \n",
    "\n",
    "Con estos dos pasos es posible calcular la probabilidad de que el modelo genere una secuencia de observaciones dada.\n",
    "\n",
    "*Jurafsky, D., & Martin, J. H. (2024). Speech and Language Processing. Recuperado de https://web.stanford.edu/~jurafsky/slp3/A.pdf*\n",
    "\n",
    "4. En el algoritmo de Forward Backward, por qué es necesario el paso de Backward (puede escribir ejemplos\n",
    "o casos para responder esta pregunta.\n",
    "\n",
    "Sabiendo que forward consiste en una suma de pesos de caminos desde “start” a “H i =h i ” y backward consiste en la suma de pesos de caminos desde “H i =h i ” a “end. Backward es de suma importancia para poder tener una probabilidad mas exacta, analizando los estados siguientes y no únicamente los anteriores. Con el paso Backward podemos saber como un estado lleva a observaciones futuras, haciendo que la probabilidad sea más precisa como se mencionó anteriormente y aportando un contexto futuro a cada estado. *(Suriano.A, 2024)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Algoritmo Forward Backward en HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, states: list[str], observations: list[str], initial_prob: dict[str, int], transition_prob: dict[str, dict[str, int]], emission_prob: dict[str, dict[str, int]]):\n",
    "        self.states: list[str] = states  # Lista de estados posibles del HMM\n",
    "        self.observations: list[str] = observations  # Lista de observaciones posibles del HMM\n",
    "        self.initial_prob: dict[str, int] = initial_prob  # Probabilidad inicial de cada estado\n",
    "        self.transition_prob: dict[str, dict[str, int]] = transition_prob  # Probabilidad de transición entre estados. Se refiere a la probabilidad de pasar de un estado a otro\n",
    "        self.emission_prob: dict[str, dict[str, int]] = emission_prob  # Probabilidad de emitir una observación dado un estado. Se refiere a la probabilidad de observar una secuencia de observaciones dado un estado\n",
    "\n",
    "    def generate_sequence(self, length: int):\n",
    "        \"\"\" Generar una secuencia de observaciones basadas en el HMM\"\"\"\n",
    "        sequence = []\n",
    "        state = random.choices(self.states, weights=[self.initial_prob[s] for s in self.states])[0]\n",
    "        for _ in range(length):\n",
    "            # Seleccionar una observación basada en la probabilidad de emisión del estado actual\n",
    "            observation = random.choices(self.observations, weights=[self.emission_prob[state][o] for o in self.observations])[0]\n",
    "            sequence.append((state, observation))\n",
    "            state = random.choices(self.states, weights=[self.transition_prob[state][s] for s in self.states])[0]\n",
    "        return sequence\n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        \"\"\" Implementar el paso forward del algoritmo forward-backward\"\"\"\n",
    "        forward_prob = []\n",
    "        for i, (state, observation) in enumerate(sequence):\n",
    "            if i == 0:  # Incialización con las probabilidades del estado inicial multiplicadas por las probabilidades de emisión.\n",
    "                forward_prob.append({s: self.initial_prob[s] * self.emission_prob[s][observation] for s in self.states})\n",
    "            else:  # Se calcula la probabilidad de cada estado basandose en la probabilidad de los estados anteriores\n",
    "                forward_prob.append({s: sum(forward_prob[i - 1][s1] * self.transition_prob[s1][s] * self.emission_prob[s][observation] for s1 in self.states) for s in self.states})\n",
    "        return forward_prob\n",
    "    \n",
    "    def backward(self, sequence):\n",
    "        \"\"\" Implementar el paso backward del algoritmo forward-backward\"\"\"\n",
    "        backward_prob = [{} for _ in sequence]  # Lista de diccionarios para almacenar las probabilidades backward\n",
    "        for i in range(len(sequence) - 1, -1, -1):\n",
    "            state, observation = sequence[i]\n",
    "            if i == len(sequence) - 1:  # Inicialización con las probabilidades del estado final multiplicadas por las probabilidades de emisión\n",
    "                backward_prob[i] = {s: 1 for s in self.states}  # Inicialización con 1\n",
    "            else:  # Se calcula la probabilidad backward de cada estado basandose en la probabilidad de los estados siguientes \n",
    "                backward_prob[i] = {s: sum(self.transition_prob[s][s1] * self.emission_prob[s1][sequence[i + 1][1]] * backward_prob[i + 1][s1] for s1 in self.states) for s in self.states}  # Cálculo de la probabilidad backward \n",
    "        \n",
    "        return backward_prob\n",
    "    \n",
    "    def compute_state_probability(self, sequence):\n",
    "        \"\"\" Combine probabilidades forward y backward para obtener la probabilidad de un estado \"\"\"\n",
    "        forward_prob = self.forward(sequence)\n",
    "        backward_prob = self.backward(sequence)\n",
    "        # Combinación de probabilidades forward y backward para obtener la probabilidad de un estadoi\n",
    "        state_prob = [{s: forward_prob[i][s] * backward_prob[i][s] for s in self.states} for i in range(len(sequence))]\n",
    "        return state_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso y datos\n",
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Sunny', 'Rainy'] \n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}}\n",
    "emission_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}}\n",
    "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia de observaciones generada: [('Sunny', 'Sunny'), ('Sunny', 'Sunny'), ('Rainy', 'Sunny'), ('Rainy', 'Sunny'), ('Rainy', 'Rainy')]\n",
      "Probabilidades forward: [{'Sunny': 0.4, 'Rainy': 0.15}, {'Sunny': 0.30400000000000005, 'Rainy': 0.051000000000000004}, {'Sunny': 0.21088000000000007, 'Rainy': 0.027420000000000003}, {'Sunny': 0.14373760000000008, 'Rainy': 0.017588400000000004}, {'Sunny': 0.024405088000000012, 'Rainy': 0.02751039200000001}]\n",
      "Probabilidades backward: [{'Sunny': 0.10434480000000007, 'Rainy': 0.06785040000000003}, {'Sunny': 0.15324000000000007, 'Rainy': 0.10452000000000003}, {'Sunny': 0.22200000000000006, 'Rainy': 0.18600000000000003}, {'Sunny': 0.30000000000000004, 'Rainy': 0.5}, {'Sunny': 1, 'Rainy': 1}]\n",
      "Probabilidades de estados: [{'Sunny': 0.04173792000000003, 'Rainy': 0.010177560000000004}, {'Sunny': 0.04658496000000003, 'Rainy': 0.005330520000000002}, {'Sunny': 0.04681536000000003, 'Rainy': 0.005100120000000001}, {'Sunny': 0.04312128000000003, 'Rainy': 0.008794200000000002}, {'Sunny': 0.024405088000000012, 'Rainy': 0.02751039200000001}]\n"
     ]
    }
   ],
   "source": [
    "# Generar una secuencia de observaciones\n",
    "obs_seq = hmm.generate_sequence(5)\n",
    "print(\"Secuencia de observaciones generada:\", obs_seq)\n",
    "\n",
    "#Calculo de probabilidades forward\n",
    "forward_prob = hmm.forward(obs_seq)\n",
    "print(\"Probabilidades forward:\", forward_prob)\n",
    "\n",
    "#Calculo de probabilidades backward\n",
    "backward_prob = hmm.backward(obs_seq)\n",
    "print(\"Probabilidades backward:\", backward_prob)\n",
    "\n",
    "#Calculo de probabilidades de estados\n",
    "state_prob = hmm.compute_state_probability(obs_seq)\n",
    "print(\"Probabilidades de estados:\", state_prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
